{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01cf7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Standard library\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Third-party libraries\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Scikit-learn - core modules\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Scikit-learn - metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, average_precision_score, balanced_accuracy_score,\n",
    "    ConfusionMatrixDisplay, f1_score, log_loss,\n",
    "    matthews_corrcoef, mean_squared_error, precision_score,\n",
    "    PrecisionRecallDisplay, r2_score, recall_score, roc_auc_score, RocCurveDisplay\n",
    ")\n",
    "\n",
    "# Local application/library imports\n",
    "from utils import load_search_space, get_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9618e627",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d5cd5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 64\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a53582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Info\n",
    "# adult_income_cleaned, framingham_cleaned, preprocessed_heloc, diabetes\n",
    "dataset_name = 'adult'        \n",
    "dataset_subpath = 'Binary/adult'       \n",
    "task_type = 'Binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e50c034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"./data/{dataset_subpath}/{dataset_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f6503d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48842, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e3c9347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass    fnlwgt     education  education-num      marital-status  \\\n",
       "0   25    Private  226802.0          11th              7       Never-married   \n",
       "1   38    Private   89814.0       HS-grad              9  Married-civ-spouse   \n",
       "2   28  Local-gov  336951.0    Assoc-acdm             12  Married-civ-spouse   \n",
       "3   44    Private  160323.0  Some-college             10  Married-civ-spouse   \n",
       "4   18        NaN  103497.0  Some-college             10       Never-married   \n",
       "\n",
       "          occupation relationship   race     sex  capital-gain  capital-loss  \\\n",
       "0  Machine-op-inspct    Own-child  Black    Male           0.0           0.0   \n",
       "1    Farming-fishing      Husband  White    Male           0.0           0.0   \n",
       "2    Protective-serv      Husband  White    Male           0.0           0.0   \n",
       "3  Machine-op-inspct      Husband  Black    Male        7688.0           0.0   \n",
       "4                NaN    Own-child  White  Female           0.0           0.0   \n",
       "\n",
       "   hours-per-week native-country  class  \n",
       "0              40  United-States  <=50K  \n",
       "1              50  United-States  <=50K  \n",
       "2              40  United-States   >50K  \n",
       "3              40  United-States   >50K  \n",
       "4              30  United-States  <=50K  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f254feb5",
   "metadata": {},
   "source": [
    "## LOAD AND PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6863f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, dataset_name, task_type, seed=42):\n",
    "    task_type = task_type.lower()\n",
    "\n",
    "    # Load config\n",
    "    with open(f\"./configs/preprocess/{dataset_name}.json\") as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    categorical_cols = config[\"categorical_cols\"]\n",
    "    numerical_cols = config[\"numerical_cols\"]\n",
    "    encoding = config[\"encoding\"]\n",
    "\n",
    "    # Extract features and target\n",
    "    X = df[numerical_cols + categorical_cols].copy()\n",
    "    y = df.iloc[:, -1].copy()\n",
    "\n",
    "    # Encode target if needed\n",
    "    le = None\n",
    "    if encoding.get(\"target\") == \"label\":\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "        label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    else:\n",
    "        label_mapping = None\n",
    "\n",
    "    # Split raw data before transformation\n",
    "    if task_type == \"regression\":\n",
    "        # For regression, we can use a simple split\n",
    "        X_train_raw, X_temp_raw, y_train, y_temp = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=seed\n",
    "        )\n",
    "        X_val_raw, X_test_raw, y_val, y_test = train_test_split(\n",
    "            X_temp_raw, y_temp, test_size=0.5, random_state=seed\n",
    "        )\n",
    "    else:\n",
    "        # For classification, we need stratified splits\n",
    "        X_train_raw, X_temp_raw, y_train, y_temp = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=seed, stratify=y\n",
    "        )\n",
    "        X_val_raw, X_test_raw, y_val, y_test = train_test_split(\n",
    "            X_temp_raw, y_temp, test_size=0.5, random_state=seed, stratify=y_temp\n",
    "        )\n",
    "\n",
    "    # Ensure y_* are Series with index matching the X_*\n",
    "    y_train = pd.Series(y_train, index=X_train_raw.index)\n",
    "    y_val = pd.Series(y_val, index=X_val_raw.index)\n",
    "    y_test = pd.Series(y_test, index=X_test_raw.index)\n",
    "\n",
    "    # Compute class weights for classification\n",
    "    class_weight = None\n",
    "    if task_type in [\"binary\", \"multiclass\"]:\n",
    "        class_weight_values = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "        class_weight = dict(zip(np.unique(y_train), class_weight_values))\n",
    "        print(f\"Class weights: {class_weight}\")\n",
    "\n",
    "    # Transform numerical and categorical features\n",
    "    transformers = []\n",
    "\n",
    "    if encoding[\"numerical_features\"] == \"minmax\":\n",
    "        transformers.append((\"num\", MinMaxScaler(), numerical_cols))\n",
    "    elif encoding[\"numerical_features\"] == \"standard\":\n",
    "        transformers.append((\"num\", StandardScaler(), numerical_cols))\n",
    "\n",
    "    if categorical_cols and encoding[\"categorical_features\"] == \"onehot\":\n",
    "        transformers.append((\"cat\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), categorical_cols))\n",
    "\n",
    "    if transformers:\n",
    "        preprocessor = ColumnTransformer(transformers=transformers)\n",
    "        X_train = preprocessor.fit_transform(X_train_raw)\n",
    "        X_val = preprocessor.transform(X_val_raw)\n",
    "        X_test = preprocessor.transform(X_test_raw)\n",
    "\n",
    "        # Recover transformed column names\n",
    "        if \"cat\" in preprocessor.named_transformers_:\n",
    "            cat_feature_names = preprocessor.named_transformers_[\"cat\"].get_feature_names_out(categorical_cols)\n",
    "            all_feature_names = numerical_cols + list(cat_feature_names)\n",
    "        else:\n",
    "            all_feature_names = numerical_cols + categorical_cols\n",
    "\n",
    "        X_train = pd.DataFrame(X_train, columns=all_feature_names, index=X_train_raw.index)\n",
    "        X_val = pd.DataFrame(X_val, columns=all_feature_names, index=X_val_raw.index)\n",
    "        X_test = pd.DataFrame(X_test, columns=all_feature_names, index=X_test_raw.index)\n",
    "    else:\n",
    "        all_feature_names = numerical_cols + categorical_cols  # or keep original order\n",
    "        X_train = pd.DataFrame(X_train_raw, columns=all_feature_names, index=X_train_raw.index)\n",
    "        X_val = pd.DataFrame(X_val_raw, columns=all_feature_names, index=X_val_raw.index)\n",
    "        X_test = pd.DataFrame(X_test_raw, columns=all_feature_names, index=X_test_raw.index)\n",
    "\n",
    "    print(f\"Shapes — Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "    print(f\"Numerical features: {len(numerical_cols)} — {numerical_cols}\")\n",
    "    print(f\"Categorical features: {len(categorical_cols)} — {categorical_cols}\")\n",
    "    print(f\"Total features: {X_train.shape[1]}\")\n",
    "    if label_mapping:\n",
    "        print(f\"Target label mapping: {label_mapping}\")\n",
    "\n",
    "    return (\n",
    "        X_train, X_val, X_test,\n",
    "        y_train, y_val, y_test,\n",
    "        None, le, class_weight\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11d7590",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d74adbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.6572785296831745, 1: 2.089536731450923}\n",
      "Shapes — Train: (34189, 108), Val: (7326, 108), Test: (7327, 108)\n",
      "Numerical features: 6 — ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "Categorical features: 8 — ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
      "Total features: 108\n",
      "Target label mapping: {'<=50K': 0, '>50K': 1}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, categorical_cols, label_encoder, class_weight = preprocess_data(df, dataset_name=dataset_name, task_type=task_type, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b450ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes — Train: (34189, 109), Val: (7326, 109), Test: (7327, 109)\n"
     ]
    }
   ],
   "source": [
    "# 2. Concatenate X and y (label as last column)\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "val_df = pd.concat([X_val, y_val], axis=1)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "print(f\"Shapes — Train: {train_df.shape}, Val: {val_df.shape}, Test: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83294ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_images import generate_images_from_config, load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da2c4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images with config: TINTO_blur\n",
      "\n",
      "Generating images with config: TINTO_noblur\n",
      "\n",
      "Generating images with config: IGTD\n",
      "\n",
      "[IGTD] Auto-calculated image size: [11, 11]\n",
      "Generating images with config: REFINED\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.10/site-packages/sklearn/manifold/_mds.py:677: FutureWarning: The default value of `n_init` will change from 4 to 1 in 1.9.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config_path = f\"configs/image_generation/{dataset_name}.json\"\n",
    "config = load_config(config_path)\n",
    "\n",
    "generate_images_from_config(\n",
    "    config=config,\n",
    "    X_train=train_df,\n",
    "    X_val=val_df,\n",
    "    X_test=test_df,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84b55eec-acb6-448f-a9b6-6f638981cf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[warn] missing dir: SyntheticImages/Binary/adult/BIE/train/images\n",
      "[warn] missing dir: SyntheticImages/Binary/adult/BIE/val/images\n",
      "[warn] missing dir: SyntheticImages/Binary/adult/BIE/test/images\n",
      "\n",
      "Done. Total: 0, padded: 0, already square: 0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Base folder containing train/val/test\n",
    "BASE = Path(f\"SyntheticImages/{task_type}/{dataset_name}/BIE\")\n",
    "SPLITS = [\"train\", \"val\", \"test\"]\n",
    "SUB = \"images\"\n",
    "\n",
    "# Padding background color\n",
    "RGB_PAD_COLOR = (0, 0, 0)  # white\n",
    "\n",
    "def pad_to_square_right_or_bottom(im: Image.Image) -> Image.Image:\n",
    "    \"\"\"Pad image to square by extending to the right (if wider) or bottom (if taller) with black background.\"\"\"\n",
    "    w, h = im.size\n",
    "    if w == h:\n",
    "        return im  # already square\n",
    "\n",
    "    size = max(w, h)\n",
    "\n",
    "    # Ensure RGB mode\n",
    "    if im.mode != \"RGB\":\n",
    "        im = im.convert(\"RGB\")\n",
    "\n",
    "    new_im = Image.new(\"RGB\", (size, size), RGB_PAD_COLOR)\n",
    "\n",
    "    if w > h:\n",
    "        # wider → paste at top-left, pad bottom\n",
    "        new_im.paste(im, (0, 0))\n",
    "    else:\n",
    "        # taller → paste at top-left, pad right\n",
    "        new_im.paste(im, (0, 0))\n",
    "\n",
    "    return new_im\n",
    "\n",
    "def is_image(fname: str) -> bool:\n",
    "    return fname.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "\n",
    "# Run the padding\n",
    "count_total, count_padded, count_skipped = 0, 0, 0\n",
    "for split in SPLITS:\n",
    "    img_dir = BASE / split / SUB\n",
    "    if not img_dir.exists():\n",
    "        print(f\"[warn] missing dir: {img_dir}\")\n",
    "        continue\n",
    "    for fname in os.listdir(img_dir):\n",
    "        if not is_image(fname):\n",
    "            continue\n",
    "        path = img_dir / fname\n",
    "        try:\n",
    "            with Image.open(path) as im:\n",
    "                count_total += 1\n",
    "                if im.size[0] == im.size[1]:\n",
    "                    count_skipped += 1\n",
    "                    continue\n",
    "                out = pad_to_square_one_side(im)\n",
    "                out.save(path, format=im.format)  # overwrite\n",
    "                count_padded += 1\n",
    "        except Exception as e:\n",
    "            print(f\"[error] {path}: {e}\")\n",
    "\n",
    "print(f\"\\nDone. Total: {count_total}, padded: {count_padded}, already square: {count_skipped}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5429dc2-1245-4632-a3ce-e8d55fc9cb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[skip non-folder] SyntheticImages/Binary/adult/BIE/train/supervised.csv\n",
      "[skip non-folder] SyntheticImages/Binary/adult/BIE/val/supervised.csv\n",
      "[skip non-folder] SyntheticImages/Binary/adult/BIE/test/supervised.csv\n",
      "\n",
      "Done. Total: 48842, padded: 48842, already square: 0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# Base folder containing train/val/test\n",
    "BASE = Path(f\"SyntheticImages/{task_type}/{dataset_name}/BIE\")\n",
    "SPLITS = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# Padding background color\n",
    "RGB_PAD_COLOR = (0, 0, 0)  # black\n",
    "\n",
    "\n",
    "def pad_to_square_right_or_bottom(im: Image.Image) -> Image.Image:\n",
    "    \"\"\"Pad image to square by extending to the right (if wider) or bottom (if taller) with black background.\"\"\"\n",
    "    w, h = im.size\n",
    "    if w == h:\n",
    "        return im  # already square\n",
    "\n",
    "    size = max(w, h)\n",
    "\n",
    "    # Ensure RGB mode\n",
    "    if im.mode != \"RGB\":\n",
    "        im = im.convert(\"RGB\")\n",
    "\n",
    "    new_im = Image.new(\"RGB\", (size, size), RGB_PAD_COLOR)\n",
    "\n",
    "    if w > h:\n",
    "        # wider → paste at top-left, pad bottom\n",
    "        new_im.paste(im, (0, 0))\n",
    "    else:\n",
    "        # taller → paste at top-left, pad right\n",
    "        new_im.paste(im, (0, 0))\n",
    "\n",
    "    return new_im\n",
    "\n",
    "\n",
    "def is_image(fname: str) -> bool:\n",
    "    return fname.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
    "\n",
    "\n",
    "# Run the padding\n",
    "count_total, count_padded, count_skipped = 0, 0, 0\n",
    "for split in SPLITS:\n",
    "    split_dir = BASE / split\n",
    "    if not split_dir.exists():\n",
    "        print(f\"[warn] missing dir: {split_dir}\")\n",
    "        continue\n",
    "\n",
    "    # Loop over folders directly inside train/val/test\n",
    "    for class_dir in split_dir.iterdir():\n",
    "        if not class_dir.is_dir():\n",
    "            print(f\"[skip non-folder] {class_dir}\")\n",
    "            continue\n",
    "\n",
    "        for path in class_dir.iterdir():\n",
    "            if not path.is_file() or not is_image(path.name):\n",
    "                continue\n",
    "            try:\n",
    "                with Image.open(path) as im:\n",
    "                    count_total += 1\n",
    "                    if im.size[0] == im.size[1]:\n",
    "                        count_skipped += 1\n",
    "                        continue\n",
    "                    out = pad_to_square_right_or_bottom(im)\n",
    "                    out.save(path, format=im.format)  # overwrite\n",
    "                    count_padded += 1\n",
    "            except Exception as e:\n",
    "                print(f\"[error] {path}: {e}\")\n",
    "\n",
    "print(f\"\\nDone. Total: {count_total}, padded: {count_padded}, already square: {count_skipped}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be9bdf-44b1-47fb-8e91-9e69b1d9bc61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
